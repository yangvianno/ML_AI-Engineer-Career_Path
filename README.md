# ðŸ“‰ Visualizing Gradient Descent with Different Learning Rates

This project demonstrates how **gradient descent** updates the parameters of a simple linear regression model using **different learning rates**. It uses `matplotlib` animation to visualize how the regression line adjusts step-by-step.

## ðŸ§  What It Does

- Implements gradient descent for a linear model: `y = mx + b`
- Trains the model using three learning rates: `0.001`, `0.01`, and `0.1`
- Animates the training process for each learning rate to show:
  - How fast (or slow) the line converges
  - How large learning rates may overshoot
